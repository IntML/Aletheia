{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T03:24:04.778859Z",
     "start_time": "2021-02-10T03:24:04.280830Z"
    },
    "id": "1PHCu_AGewH9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KF-k36mewII"
   },
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T03:24:05.154648Z",
     "start_time": "2021-02-10T03:24:04.781138Z"
    },
    "id": "lob4PeDlewIJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_boston()\n",
    "x = MinMaxScaler().fit_transform(data.data)\n",
    "y = MinMaxScaler().fit_transform(data.target.reshape(-1, 1))\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k948ct0ZewIJ"
   },
   "source": [
    "Train PLNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T03:37:53.807981Z",
     "start_time": "2021-02-10T03:37:53.739196Z"
    },
    "id": "frwkodTqewIK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class ModelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"Constructor to initialize data and class labels.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            A numpy ndarray of shape (n_samples,n_features)\n",
    "        labels : np.ndarray\n",
    "            A numpy ndarray of shape (n_classes)\n",
    "        \"\"\"\n",
    "        super(ModelDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx) -> torch.tensor:\n",
    "        \"\"\"Support the indexing such that data[idx], label[idx] can be used to get ith sample\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx :\n",
    "            Indices/Keys to get the ith sample of data and labels\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            data: torch.Tensor of size (batch_size,n_features)\n",
    "            labels: torch.Tensor of size (batch_size)\n",
    "        \"\"\"\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"To return the size of the dataset using len(data)\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            size of dataset\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_dataloader(self, batch_size: int, num_workers: int = 0, shuffle: bool = False, batch_first: bool = True, pin_memory: bool = False) -> object:\n",
    "        \"\"\"Initializes the  DataLoader class. It combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            how many samples per batch to load\n",
    "        num_workers : int, optional\n",
    "            how many subprocesses to use for data loading, by default 0\n",
    "        shuffle : bool, optional\n",
    "            set to True to have the data reshuffled at every epoch, by default False\n",
    "        batch_first : bool, optional\n",
    "            Samples the data such that batch_size should be first dimension, by default True\n",
    "        pin_memory : bool, optional\n",
    "            If True, the data loader will copy Tensors into CUDA pinned memory before returning them, by default False\n",
    "        Returns\n",
    "        -------\n",
    "        object\n",
    "            A DataLoader object to generate batch sized data\n",
    "        \"\"\"\n",
    "        batch_obj = DataLoader(self, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)\n",
    "        return batch_obj\n",
    "\n",
    "\n",
    "class ReLU_DNN(nn.Module):\n",
    "\n",
    "    def __init__(self, net_size: List[Tuple]):\n",
    "        \"\"\"Initializes a Neural Network with ReLU activation (self.net).\n",
    "        Parameters\n",
    "        ----------\n",
    "        net_size : list[tuple], len(list) is n_layers\n",
    "            Layer sizes (tuple) (n_neurons[n_layer], n_neurons[n_layer+1])\n",
    "        \"\"\"\n",
    "        super(ReLU_DNN, self).__init__()\n",
    "        self.layers = []\n",
    "        for size in net_size[:-1]:\n",
    "            self.layers.append(nn.Linear(size[0], size[1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(net_size[-1][0], net_size[-1][1]))\n",
    "        self.net = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Performs forward pass through the Neural Network\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input data of size (batch_size, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output from the last layer of the Neural Network.\n",
    "        \"\"\"\n",
    "        final_output = self.net(x)\n",
    "        return final_output\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes: list, epochs: int, learning_rate: float, device: str, loss_fn: torch.nn.modules.loss, l1_reg: float, l2_reg: float, batch_size: int):\n",
    "        \"\"\"Constructor for Trainer object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_layer_sizes : list\n",
    "            A list of hidden layer sizes\n",
    "        epochs : int\n",
    "            Number of training epochs\n",
    "        learning_rate : float\n",
    "            learning rate for model training\n",
    "        device : str\n",
    "            Computational device: cuda or cpu\n",
    "        loss_fn : torch.nn.modules.loss\n",
    "            Loss function used by optimizer\n",
    "            MSELoss() for regression problem\n",
    "            BCEWithLogitsLoss() for classification problem\n",
    "        l1_reg : float\n",
    "            lambda parameter for L1 Regularization\n",
    "        l2_reg : float\n",
    "            lambda parameter for L2 Regularization\n",
    "        batch_size : int\n",
    "            Batch size for training\n",
    "        \"\"\"\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.epochs = epochs\n",
    "        self.lr = learning_rate\n",
    "        self.loss_fn = loss_fn\n",
    "        self.l1_lambda = l1_reg\n",
    "        self.l2_lambda = l2_reg\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "    def validate_input(self, labels: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Reshapes the labels ndarray to (batch_size, 1) and converts entries to float data type\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : np.ndarray\n",
    "            Data labels of shape (n_classes)\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            numpy ndarray with (batch_size, 1) shape\n",
    "        \"\"\"\n",
    "        if labels.ndim != 2:\n",
    "            labels = np.reshape(labels, (-1, 1))\n",
    "        return labels.astype(float)\n",
    "\n",
    "    def get_data_loader(self, x: np.ndarray, y: np.ndarray, shuffle: bool = False) -> object:\n",
    "        \"\"\"Initializes the dataset (data, labels) and return a batch sized data loader.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Data features of shape (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Data labels of shape (n_classes)\n",
    "        shuffle : bool\n",
    "            set to True to have the data reshuffled at every epoch, by default False\n",
    "        Returns\n",
    "        -------\n",
    "        object\n",
    "            An iterator object to iterate over the data.\n",
    "        \"\"\"\n",
    "        dataobj = ModelDataset(x, y)\n",
    "        data_loader = dataobj.get_dataloader(batch_size=self.batch_size, shuffle=shuffle)\n",
    "        return data_loader\n",
    "    \n",
    "    def init_weights(self,layer):\n",
    "        \"\"\"Performs weight initialization for the network using Kaiming Normal initializer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : model layer\n",
    "            Perform initialization over model weights with Kaiming Normal initializer\n",
    "        \"\"\"\n",
    "        if type(layer) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')  \n",
    "            nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def build_model(self, data_x: np.ndarray):\n",
    "        \"\"\"Builds a ReLU DNN model\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Data features of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        input_size = data_x.shape[1]\n",
    "        output_size = 1\n",
    "        hidden_list = [input_size] + self.hidden_layer_sizes + [output_size]\n",
    "        hidden_tuples = [(hidden_list[i], hidden_list[i + 1]) for i in range(len(hidden_list) - 1)]\n",
    "        model = ReLU_DNN(hidden_tuples)\n",
    "        self.model = model.net.double()\n",
    "        self.model.apply(self.init_weights)\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(device=self.device)\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"Retrieves the parameters i.e, weights (List[torch.Tensor]) and biases (List[torch.Tensor]) of the model\n",
    "        Attributes\n",
    "        ----------\n",
    "        weights : list of shape (n_layers - 1,).\n",
    "            The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "        biases : list of shape (n_layers - 1,).\n",
    "            The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "        \"\"\"\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for name, params in self.model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                self.weights.append(torch.transpose(params, 0, 1).detach())\n",
    "            elif 'bias' in name:\n",
    "                self.biases.append(params.detach())\n",
    "\n",
    "    def calc_l1reg_loss(self, loss: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculates L1 Regularized loss\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss : torch.Tensor\n",
    "            A tensor containing loss value\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A tensor containing L1 regularized loss value\n",
    "        \"\"\"\n",
    "        l1_reg = torch.tensor(0.0, dtype=torch.double, device=self.device)\n",
    "        for name,params in self.model.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                l1_reg += torch.norm(params, 1)\n",
    "        loss = loss + self.l1_lambda * l1_reg\n",
    "        return loss\n",
    "    \n",
    "    def calc_l2reg_loss(self, loss: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculates L2 Regularized loss\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss : torch.Tensor\n",
    "            A tensor containing L2 regularized loss value\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A tensor containing L2 regularized loss value\n",
    "        \"\"\"\n",
    "        l2_reg = torch.tensor(0.0, dtype=torch.double, device=self.device)\n",
    "        for name,params in self.model.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                l2_reg += torch.norm(params, 2)**2\n",
    "        loss = loss + self.l2_lambda * l2_reg\n",
    "        return loss   \n",
    "\n",
    "    def train(self, data_loader: object):\n",
    "        \"\"\"Trains a ReLU DNN model for a given no of epochs.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_loader : object\n",
    "            An iterator object to iterate over the dataset (batch_size).\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.loss = []\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        for epochs in range(self.epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch_no, train_batch in enumerate(data_loader):\n",
    "                data, labels = train_batch[0].to(device=self.device).double(), train_batch[1].to(device=self.device).double()\n",
    "                prediction = self.model(data)\n",
    "                loss = self.loss_fn(prediction, labels)\n",
    "                if self.l1_lambda > 0.0:\n",
    "                    loss = self.calc_l1reg_loss(loss)\n",
    "                if self.l2_lambda > 0.0:\n",
    "                    loss = self.calc_l2reg_loss(loss)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            self.loss.append(epoch_loss)\n",
    "        self.get_params()\n",
    "\n",
    "\n",
    "class ReluNetRegressor(Trainer):\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes: list, epochs: int, device: str, learning_rate: float = 0.01, l1_reg: float = 0, l2_reg: float = 0, batch_size: int = 100):\n",
    "        \"\"\"Regressor object inherits Trainer object.\n",
    "           This function is the constructor for both Trainer and Regressor objects.\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_layer_sizes : list\n",
    "            A list of hidden layer sizes\n",
    "        epochs : int\n",
    "            Number of training epochs\n",
    "        device : str\n",
    "            Computational device: cuda or cpu\n",
    "        learning_rate : float, optional\n",
    "            learning rate for model training, by default 0.01\n",
    "        l1_reg : float, optional\n",
    "            lambda parameter for L1 Regularization, by default 0\n",
    "        l2_reg : float, optional\n",
    "            lambda parameter for L2 Regularization, by default 0\n",
    "        batch_size : int, optional\n",
    "            Batch size for training, by default 100\n",
    "        \"\"\"\n",
    "        super(ReluNetRegressor, self).__init__(hidden_layer_sizes=hidden_layer_sizes, epochs=epochs, learning_rate=learning_rate, device=device, loss_fn=nn.MSELoss(), l1_reg=l1_reg, l2_reg=l2_reg, batch_size=batch_size)\n",
    "\n",
    "    def fit(self, data_x: np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"Builds a ReLU DNN model for given data and calls train function to train the model\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Training data features of shape (n_samples, n_features)\n",
    "        labels : np.ndarray\n",
    "            Training data labels of shape (n_classes)\n",
    "        \"\"\"\n",
    "        labels = self.validate_input(labels)\n",
    "        self.build_model(data_x)\n",
    "        data_loader = self.get_data_loader(x=data_x, y=labels, shuffle=True)\n",
    "        self.train(data_loader)\n",
    "\n",
    "    def perform_eval(self, data_x: np.ndarray, labels: np.ndarray) -> float:\n",
    "        \"\"\"Performs evaluation on the test data using trained model and returns r2 score of the model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Test data features of shape (n_samples, n_features)\n",
    "        labels : np.ndarray\n",
    "            Test data labels of shape (n_classes)\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            r2 score of the model on test data\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.batch_size = data_x.shape[0]\n",
    "        labels = self.validate_input(labels)\n",
    "        data_loader = self.get_data_loader(x=data_x, y=labels, shuffle=False)\n",
    "        for batch_no, val_batch in enumerate(data_loader):\n",
    "            data, labels = val_batch[0].to(device=self.device).double(), val_batch[1].to(device=self.device).double()\n",
    "            with torch.no_grad():\n",
    "                prediction = self.model(data)\n",
    "        error = torch.sum(torch.pow(prediction - labels, 2)).item()\n",
    "        y_sum = torch.sum(torch.pow(labels - torch.mean(labels), 2)).item()\n",
    "        r2_score = 1 - error / (y_sum)\n",
    "        return r2_score\n",
    "\n",
    "    def predict(self, data_x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Returns numpy array of predicted values for test data\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Test data features of shape (n_samples, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            numpy array of predicted values\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        data = torch.from_numpy(data_x).to(device=self.device)\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(data.double())\n",
    "        return prediction.cpu().numpy()\n",
    "\n",
    "\n",
    "class ReluNetClassifier(Trainer):\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes: list, epochs: int, device: str, learning_rate: float = 0.01, l1_reg: float = 0, l2_reg: float = 0, batch_size: int = 100):\n",
    "        \"\"\"Classifier object inherits Trainer object.\n",
    "           This function is the constructor for both Trainer and Classifier objects.\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_layer_sizes : list\n",
    "            A list of hidden layer sizes\n",
    "        epochs : int\n",
    "            Number of training epochs\n",
    "        device : str\n",
    "            Computational device: cuda or cpu\n",
    "        learning_rate : float, optional\n",
    "            learning rate for model training, by default 0.01\n",
    "        l1_reg : float, optional\n",
    "            lambda parameter for L1 Regularization, by default 0\n",
    "        l2_reg : float, optional\n",
    "            lambda parameter for L2 Regularization, by default 0\n",
    "        batch_size : int, optional\n",
    "            Batch size for training, by default 100\n",
    "        \"\"\"\n",
    "        super(ReluNetClassifier, self).__init__(hidden_layer_sizes=hidden_layer_sizes, epochs=epochs, learning_rate=learning_rate, device=device, loss_fn=nn.BCEWithLogitsLoss(), l1_reg=l1_reg, l2_reg=l2_reg, batch_size=batch_size)\n",
    "\n",
    "    def fit(self, data_x: np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"Builds a ReLU DNN model for given data and calls train function to train the model\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Training data features of shape (n_samples, n_features)\n",
    "        labels : np.ndarray\n",
    "            Training data labels of shape (n_classes)\n",
    "        \"\"\"\n",
    "        labels = self.validate_input(labels)\n",
    "        self.build_model(data_x)\n",
    "        data_loader = self.get_data_loader(x=data_x, y=labels, shuffle=True)\n",
    "        self.train(data_loader)\n",
    "\n",
    "    def perform_eval(self, data_x: np.ndarray, labels: np.ndarray) -> float:\n",
    "        \"\"\"Performs evaluation on the test data using trained model and returns accuracy of the model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Test data features of shape (n_samples, n_features)\n",
    "        labels : np.ndarray\n",
    "            Test data labels of shape (n_classes)\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Accuracy of the model on test data\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.batch_size = data_x.shape[0]\n",
    "        labels = self.validate_input(labels)\n",
    "        data_loader = self.get_data_loader(x=data_x, y=labels, shuffle=False)\n",
    "        for batch_no, val_batch in enumerate(data_loader):\n",
    "            data, labels = val_batch[0].to(device=self.device).double(), val_batch[1].to(device=self.device).double()\n",
    "            with torch.no_grad():\n",
    "                prediction = self.model(data)\n",
    "                pred_labels = torch.round(torch.sigmoid(prediction))\n",
    "                correct_results_sum = (pred_labels == labels).sum().float()\n",
    "                acc = correct_results_sum / labels.shape[0]\n",
    "                acc = torch.round(acc * 100)\n",
    "        return acc.item()\n",
    "\n",
    "    def predict_proba(self, data_x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Returns numpy array of predicted probabilities of being classified as class 1 on test data\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_x : np.ndarray\n",
    "            Test data features of shape (n_samples, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            numpy array of predicted probabilities\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        data = torch.from_numpy(data_x).to(device=self.device)\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(data.double())\n",
    "            proba = torch.sigmoid(prediction)\n",
    "        return proba.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WKutf9cTpfC4"
   },
   "outputs": [],
   "source": [
    "#Reproducibility seed\n",
    "def set_seed(seed):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T03:40:07.007149Z",
     "start_time": "2021-02-10T03:39:25.862243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "HHBJ7xgiewIS",
    "outputId": "154a518f-f62f-49df-d9ad-947195b9355c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Response Mean</th>\n",
       "      <th>Response Std</th>\n",
       "      <th>Local MSE</th>\n",
       "      <th>Global MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.0</td>\n",
       "      <td>0.278137</td>\n",
       "      <td>0.082941</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.028025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.598912</td>\n",
       "      <td>0.178224</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.091237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>0.415382</td>\n",
       "      <td>0.101684</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.043052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.149206</td>\n",
       "      <td>0.076133</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.044379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.408244</td>\n",
       "      <td>0.171462</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.049419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.216921</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>0.068777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.829722</td>\n",
       "      <td>0.162723</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.045385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.105079</td>\n",
       "      <td>0.092839</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.109257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count  Response Mean  Response Std  Local MSE  Global MSE\n",
       "0  136.0       0.278137      0.082941   0.002789    0.028025\n",
       "1   98.0       0.598912      0.178224   0.006719    0.091237\n",
       "2   77.0       0.415382      0.101684   0.003404    0.043052\n",
       "3   35.0       0.149206      0.076133   0.003979    0.044379\n",
       "4   31.0       0.408244      0.171462   0.008261    0.049419\n",
       "5   12.0       0.363333      0.216921   0.013247    0.068777\n",
       "6    8.0       0.829722      0.162723   0.002904    0.045385\n",
       "7    7.0       0.105079      0.092839   0.008752    0.109257"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aletheia\n",
    "best_reg = 0.001\n",
    "set_seed(0)\n",
    "mlp = ReluNetRegressor(hidden_layer_sizes=[40] * 4, epochs=2000, device=\"cpu\",\n",
    "                       learning_rate=0.001, l1_reg=best_reg, batch_size=100)\n",
    "mlp.fit(train_x, train_y)\n",
    "coefs = [item.numpy() for item in mlp.weights]\n",
    "intercepts = [item.numpy() for item in mlp.biases]\n",
    "clf = aletheia.UnwrapperRegressor(coefs, intercepts)\n",
    "clf.fit(train_x, train_y)\n",
    "clf.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "demo-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
